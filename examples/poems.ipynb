{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3006df97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imports successful!\n",
      "CUDA available: True\n",
      "Current device: 0\n",
      "Device name: NVIDIA H100 80GB HBM3\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append('../')\n",
    "\n",
    "import torch\n",
    "from typing import List, Dict, Any, Optional, Tuple\n",
    "\n",
    "# Import the necessary functions from plan_trace\n",
    "from plan_trace.utils import load_model, load_pretrained_saes, cleanup_cuda\n",
    "from plan_trace.circuit_discovery import discover_circuit\n",
    "from plan_trace.logit_lens import find_logit_lens_clusters  \n",
    "from plan_trace.steering import run_steering_sweep\n",
    "from plan_trace.pipeline import run_single_token_analysis, analyze_planning_evidence\n",
    "\n",
    "print(\"Imports successful!\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"Current device: {torch.cuda.current_device()}\")\n",
    "    print(f\"Device name: {torch.cuda.get_device_name()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f671e8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:You tried to specify center_unembed=True for a model using logit softcap, but this can't be done! Softcapping is not invariant upon adding a constantSetting center_unembed=False instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model and SAEs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a99255f8dc264829b6c366ccc8ef3641",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:With reduced precision, it is advised to use `from_pretrained_no_processing` instead of `from_pretrained`.\n",
      "WARNING:root:You are not using LayerNorm, so the writing weights can't be centered! Skipping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gemma-2-2b-it into HookedTransformer\n",
      "Model loaded: gemma-2-2b-it\n",
      "Number of layers: 26\n",
      "SAEs loaded for 26 layers\n"
     ]
    }
   ],
   "source": [
    "# Load model and SAEs\n",
    "print(\"Loading model and SAEs...\")\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model_name = \"gemma-2-2b-it\"\n",
    "\n",
    "model = load_model(model_name, device=device, use_custom_cache=True, dtype=torch.bfloat16)\n",
    "layers = list(range(model.cfg.n_layers))\n",
    "saes = load_pretrained_saes(\n",
    "    layers=layers, \n",
    "    release=\"gemma-scope-2b-pt-mlp-canonical\", \n",
    "    width=\"16k\", \n",
    "    device=device, \n",
    "    canon=True\n",
    ")\n",
    "\n",
    "print(f\"Model loaded: {model_name}\")\n",
    "print(f\"Number of layers: {model.cfg.n_layers}\")\n",
    "print(f\"SAEs loaded for {len(saes)} layers\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c3f285a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: 'A rhyming couplet:\n",
      "He saw a carrot and had to grab it,\n",
      "'\n",
      "Newline token ID: 108\n",
      "Double newline token ID: 109\n",
      "Prompt tokens: tensor([[     2, 235280, 227365,   5591, 235251, 235292,    108,   1949,   4818,\n",
      "            476,  64058,    578,   1093,    577,  15476,    665, 235269,    108]],\n",
      "       device='cuda:0')\n",
      "Prompt length: 18 tokens\n",
      "Prompt decoded: '<bos>A rhyming couplet:\n",
      "He saw a carrot and had to grab it,\n",
      "'\n"
     ]
    }
   ],
   "source": [
    "# Define the prompt and find newline token ID\n",
    "prompt = \"A rhyming couplet:\\nHe saw a carrot and had to grab it,\\n\"\n",
    "\n",
    "# Find the newline token ID\n",
    "newline_token = model.to_tokens(\"\\n\")[0, -1].item()  # Get the newline token ID\n",
    "double_newline_token = model.to_tokens(\"\\n\\n\")[0, -1].item()  # Get the double newline token ID\n",
    "print(f\"Prompt: '{prompt}'\")\n",
    "print(f\"Newline token ID: {newline_token}\")\n",
    "print(f\"Double newline token ID: {double_newline_token}\")\n",
    "\n",
    "# Tokenize the prompt\n",
    "prompt_tokens = model.to_tokens(prompt).to(device)\n",
    "prompt_length = prompt_tokens.shape[-1]\n",
    "print(f\"Prompt tokens: {prompt_tokens}\")\n",
    "print(f\"Prompt length: {prompt_length} tokens\")\n",
    "print(f\"Prompt decoded: '{model.to_string(prompt_tokens[0])}'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8ac5cad1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating sequence until newline...\n",
      "Hit newline token at position 26\n",
      "\n",
      "Complete sequence (26 tokens):\n",
      "'<bos>A rhyming couplet:\n",
      "He saw a carrot and had to grab it,\n",
      "A tasty treat, a crunchy habit.'\n",
      "\n",
      "Generated part: 'A tasty treat, a crunchy habit.\n",
      "\n",
      "'\n",
      "Generated 9 new tokens\n"
     ]
    }
   ],
   "source": [
    "# Generate the full sequence until newline\n",
    "print(\"Generating sequence until newline...\")\n",
    "\n",
    "# Start with the prompt tokens\n",
    "out_tokens = prompt_tokens.clone()\n",
    "max_new_tokens = 50  # Safety limit to prevent infinite generation\n",
    "\n",
    "generated_tokens = []\n",
    "for i in range(max_new_tokens):\n",
    "    with torch.no_grad():\n",
    "        logits = model(out_tokens)[0, -1]  # Get logits for last position\n",
    "    \n",
    "    next_token_id = logits.argmax(-1).item()\n",
    "    generated_tokens.append(next_token_id)\n",
    "    \n",
    "    # Check if we hit newline\n",
    "    if next_token_id == newline_token or next_token_id == double_newline_token:\n",
    "        print(f\"Hit newline token at position {out_tokens.shape[-1]}\")\n",
    "        break\n",
    "    \n",
    "    # Add the token to our sequence\n",
    "    out_tokens = torch.cat([out_tokens, torch.tensor([[next_token_id]], device=device)], dim=1)\n",
    "    \n",
    "    # Clean up memory\n",
    "    del logits\n",
    "    cleanup_cuda()\n",
    "\n",
    "# Get the complete sequence\n",
    "complete_text = model.to_string(out_tokens[0])\n",
    "generated_text = model.to_string(torch.tensor(generated_tokens))\n",
    "\n",
    "print(f\"\\nComplete sequence ({out_tokens.shape[-1]} tokens):\")\n",
    "print(f\"'{complete_text}'\")\n",
    "print(f\"\\nGenerated part: '{generated_text}'\")\n",
    "print(f\"Generated {len(generated_tokens)} new tokens\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dce647d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline analysis function defined!\n"
     ]
    }
   ],
   "source": [
    "def run_poem_pipeline_analysis(model, saes, out_tokens, start_pos, end_pos, verbose=True):\n",
    "    \"\"\"\n",
    "    Run pipeline analysis for each token position in the generated poem.\n",
    "    \n",
    "    Args:\n",
    "        model: The language model\n",
    "        saes: The SAE dictionaries\n",
    "        out_tokens: Complete token sequence [1, seq_len]\n",
    "        start_pos: First token position to analyze (inclusive)\n",
    "        end_pos: Last token position to analyze (exclusive)\n",
    "        verbose: Whether to print detailed progress\n",
    "    \n",
    "    Returns:\n",
    "        Dict containing results for each analyzed position\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "    \n",
    "    # Parameters for the pipeline\n",
    "    ig_steps = 10\n",
    "    k_max = 90001\n",
    "    k_step = 10000\n",
    "    k_thres = 0.6\n",
    "    coeff_grid = list(range(-100, 0, 20))\n",
    "    \n",
    "    for token_pos in range(start_pos, end_pos):\n",
    "        if verbose:\n",
    "            predicted_token = model.to_string(out_tokens[0, token_pos:token_pos+1])\n",
    "            print(f\"\\n--- Analyzing token position {token_pos}: '{predicted_token}' ---\")\n",
    "        \n",
    "        # Run single token analysis\n",
    "        token_result = run_single_token_analysis(\n",
    "            model=model,\n",
    "            saes=saes,\n",
    "            out_BL=out_tokens,\n",
    "            inter_token_id=token_pos,\n",
    "            ig_steps=ig_steps,\n",
    "            k_max=k_max,\n",
    "            k_step=k_step,\n",
    "            k_thres=k_thres,\n",
    "            coeff_grid=coeff_grid,\n",
    "            stop_token_id=double_newline_token,\n",
    "            verbose=verbose\n",
    "        )\n",
    "        \n",
    "        # Analyze planning evidence if successful\n",
    "        if token_result[\"status\"] == \"success\":\n",
    "            planning_analysis = analyze_planning_evidence(token_result[\"steering_results\"])\n",
    "            token_result[\"planning_analysis\"] = planning_analysis\n",
    "            \n",
    "            if verbose:\n",
    "                planning_tokens = [label for label, status in planning_analysis.items() \n",
    "                                   if status == \"planning\"]\n",
    "                if planning_tokens:\n",
    "                    print(f\"  🎯 Planning evidence found for: {planning_tokens}\")\n",
    "                else:\n",
    "                    print(f\"  ❌ No planning evidence found\")\n",
    "        elif verbose:\n",
    "            print(f\"  ⚠️ No circuit found (status: {token_result['status']})\")\n",
    "        \n",
    "        results[token_pos] = token_result\n",
    "    \n",
    "    return results\n",
    "\n",
    "print(\"Pipeline analysis function defined!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3494df45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running pipeline analysis on generated tokens...\n",
      "============================================================\n",
      "Analyzing token positions 18 to 25\n",
      "Tokens to analyze:\n",
      "  Position 18: 'A'\n",
      "  Position 19: ' tasty'\n",
      "  Position 20: ' treat'\n",
      "  Position 21: ','\n",
      "  Position 22: ' a'\n",
      "  Position 23: ' crunchy'\n",
      "  Position 24: ' habit'\n",
      "  Position 25: '.'\n",
      "\n",
      "Starting analysis...\n",
      "============================================================\n",
      "\n",
      "--- Analyzing token position 18: 'A' ---\n",
      "Baseline continuation: A tasty treat, a crunchy habit....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26it [00:25,  1.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K=1     | neg=0.0000 | abs=0.0000\n",
      "K=10001 | neg=0.0376 | abs=0.3164\n",
      "K=20001 | neg=0.0947 | abs=0.3496\n",
      "K=30001 | neg=0.0947 | abs=0.2461\n",
      "K=40001 | neg=0.0947 | abs=0.2373\n",
      "K=50001 | neg=0.0947 | abs=0.2734\n",
      "K=60001 | neg=0.0947 | abs=0.2734\n",
      "K=70001 | neg=0.0947 | abs=0.2734\n",
      "K=80001 | neg=0.0947 | abs=0.2734\n",
      "Found minimum K for absolute effects: 10001 (metric: 0.3164, target: 0.1629)\n",
      "Found circuit with 10001 entries\n",
      "Found 5 tokens not in prompt: ['.', ' crunchy', ' tasty', ' habit', ' treat']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [00:05<00:00,  4.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3 clusters: ['.', 'treat', 'tasty']\n",
      "  🎯 Planning evidence found for: ['.', 'tasty']\n",
      "\n",
      "--- Analyzing token position 19: ' tasty' ---\n",
      "Baseline continuation:  tasty treat, a crunchy habit....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26it [00:24,  1.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K=1     | neg=0.0000 | abs=0.0000\n",
      "K=10001 | neg=0.9258 | abs=0.0173\n",
      "K=20001 | neg=0.8906 | abs=0.0752\n",
      "K=30001 | neg=0.8828 | abs=0.0845\n",
      "K=40001 | neg=0.8828 | abs=0.0903\n",
      "K=50001 | neg=0.8828 | abs=0.1001\n",
      "K=60001 | neg=0.8828 | abs=0.1001\n",
      "K=70001 | neg=0.8828 | abs=0.1001\n",
      "K=80001 | neg=0.8828 | abs=0.1001\n",
      "Found minimum K for negative effects: 10001 (metric: 0.9258, target: 0.0554)\n",
      "Found minimum K for absolute effects: 20001 (metric: 0.0752, target: 0.0554)\n",
      "Found circuit with 10001 entries\n",
      "Found 5 tokens not in prompt: ['.', ' crunchy', ' tasty', ' habit', ' treat']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [00:05<00:00,  4.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3 clusters: ['.', 'tasty', 'habit']\n",
      "  🎯 Planning evidence found for: ['.', 'tasty']\n",
      "\n",
      "--- Analyzing token position 20: ' treat' ---\n",
      "Baseline continuation:  treat, a crunchy habit....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26it [00:24,  1.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K=1     | neg=0.0260 | abs=0.0260\n",
      "K=10001 | neg=0.9844 | abs=0.6250\n",
      "K=20001 | neg=0.9883 | abs=0.7578\n",
      "K=30001 | neg=0.9883 | abs=0.7305\n",
      "K=40001 | neg=0.9883 | abs=0.7305\n",
      "K=50001 | neg=0.9883 | abs=0.6992\n",
      "K=60001 | neg=0.9883 | abs=0.6992\n",
      "K=70001 | neg=0.9883 | abs=0.6992\n",
      "K=80001 | neg=0.9883 | abs=0.6992\n",
      "Found minimum K for negative effects: 10001 (metric: 0.9844, target: 0.3680)\n",
      "Found minimum K for absolute effects: 10001 (metric: 0.6250, target: 0.3680)\n",
      "Found circuit with 10001 entries\n",
      "Found 4 tokens not in prompt: ['.', ' crunchy', ' habit', ' treat']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [00:05<00:00,  4.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 clusters: ['.', 'treat']\n",
      "  🎯 Planning evidence found for: ['.', 'treat']\n",
      "\n",
      "--- Analyzing token position 21: ',' ---\n",
      "Baseline continuation: , a crunchy habit....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26it [00:24,  1.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K=1     | neg=0.5898 | abs=0.5898\n",
      "K=10001 | neg=1.0000 | abs=0.3691\n",
      "K=20001 | neg=1.0000 | abs=0.3906\n",
      "K=30001 | neg=1.0000 | abs=0.3438\n",
      "K=40001 | neg=1.0000 | abs=0.3652\n",
      "K=50001 | neg=1.0000 | abs=0.3418\n",
      "K=60001 | neg=1.0000 | abs=0.3418\n",
      "K=70001 | neg=1.0000 | abs=0.3418\n",
      "K=80001 | neg=1.0000 | abs=0.3418\n",
      "Found minimum K for negative effects: 1 (metric: 0.5898, target: 0.3000)\n",
      "Found minimum K for absolute effects: 1 (metric: 0.5898, target: 0.3000)\n",
      "Found circuit with 1 entries\n",
      "Found 3 tokens not in prompt: ['.', ' crunchy', ' habit']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  4.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 clusters: []\n",
      "  ❌ No planning evidence found\n",
      "\n",
      "--- Analyzing token position 22: ' a' ---\n",
      "Baseline continuation:  a crunchy habit....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26it [00:24,  1.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K=1     | neg=0.3379 | abs=0.3379\n",
      "K=10001 | neg=0.9844 | abs=0.3594\n",
      "K=20001 | neg=0.9922 | abs=0.2461\n",
      "K=30001 | neg=0.9922 | abs=0.1533\n",
      "K=40001 | neg=0.9922 | abs=0.1846\n",
      "K=50001 | neg=0.9922 | abs=0.2236\n",
      "K=60001 | neg=0.9922 | abs=0.2236\n",
      "K=70001 | neg=0.9922 | abs=0.2236\n",
      "K=80001 | neg=0.9922 | abs=0.2236\n",
      "Found minimum K for negative effects: 1 (metric: 0.3379, target: 0.1711)\n",
      "Found minimum K for absolute effects: 1 (metric: 0.3379, target: 0.1711)\n",
      "Found circuit with 1 entries\n",
      "Found 3 tokens not in prompt: ['.', ' crunchy', ' habit']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  4.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 clusters: []\n",
      "  ❌ No planning evidence found\n",
      "\n",
      "--- Analyzing token position 23: ' crunchy' ---\n",
      "Baseline continuation:  crunchy habit....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26it [00:25,  1.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K=1     | neg=0.0000 | abs=0.0000\n",
      "K=10001 | neg=0.9180 | abs=0.0211\n",
      "K=20001 | neg=0.9023 | abs=0.0474\n",
      "K=30001 | neg=0.8867 | abs=0.0525\n",
      "K=40001 | neg=0.8867 | abs=0.0613\n",
      "K=50001 | neg=0.8867 | abs=0.0703\n",
      "K=60001 | neg=0.8867 | abs=0.0801\n",
      "K=70001 | neg=0.8867 | abs=0.0801\n",
      "K=80001 | neg=0.8867 | abs=0.0801\n",
      "Found minimum K for negative effects: 10001 (metric: 0.9180, target: 0.0902)\n",
      "Found circuit with 10001 entries\n",
      "Found 3 tokens not in prompt: ['.', ' crunchy', ' habit']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [00:05<00:00,  4.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 clusters: ['.', 'habit']\n",
      "  🎯 Planning evidence found for: ['.']\n",
      "\n",
      "--- Analyzing token position 24: ' habit' ---\n",
      "Baseline continuation:  habit....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26it [00:25,  1.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K=1     | neg=0.0000 | abs=0.0000\n",
      "K=10001 | neg=0.9883 | abs=0.1875\n",
      "K=20001 | neg=0.9883 | abs=0.3594\n",
      "K=30001 | neg=0.9883 | abs=0.5547\n",
      "K=40001 | neg=0.9883 | abs=0.5859\n",
      "K=50001 | neg=0.9883 | abs=0.5820\n",
      "K=60001 | neg=0.9883 | abs=0.5234\n",
      "K=70001 | neg=0.9883 | abs=0.5234\n",
      "K=80001 | neg=0.9883 | abs=0.5234\n",
      "Found minimum K for negative effects: 10001 (metric: 0.9883, target: 0.3305)\n",
      "Found minimum K for absolute effects: 20001 (metric: 0.3594, target: 0.3305)\n",
      "Found circuit with 10001 entries\n",
      "Found 2 tokens not in prompt: ['.', ' habit']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [00:05<00:00,  4.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 clusters: ['.', 'habit']\n",
      "  🎯 Planning evidence found for: ['.']\n",
      "\n",
      "--- Analyzing token position 25: '.' ---\n",
      "Baseline continuation: ....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26it [00:25,  1.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K=1     | neg=0.2539 | abs=0.2539\n",
      "K=10001 | neg=0.9648 | abs=0.9727\n",
      "K=20001 | neg=0.9609 | abs=0.9727\n",
      "K=30001 | neg=0.9727 | abs=0.9531\n",
      "K=40001 | neg=0.9727 | abs=0.9102\n",
      "K=50001 | neg=0.9727 | abs=0.9531\n",
      "K=60001 | neg=0.9727 | abs=0.9414\n",
      "K=70001 | neg=0.9727 | abs=0.9414\n",
      "K=80001 | neg=0.9727 | abs=0.9414\n",
      "Found minimum K for negative effects: 10001 (metric: 0.9648, target: 0.5531)\n",
      "Found minimum K for absolute effects: 10001 (metric: 0.9727, target: 0.5531)\n",
      "Found circuit with 10001 entries\n",
      "Found 1 tokens not in prompt: ['.']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [00:05<00:00,  4.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 clusters: ['.']\n",
      "  🎯 Planning evidence found for: ['.']\n",
      "Running pipeline analysis on generated tokens...\n",
      "============================================================\n",
      "Analyzing token positions 18 to 25\n",
      "Tokens to analyze:\n",
      "  Position 18: 'A'\n",
      "  Position 19: ' tasty'\n",
      "  Position 20: ' treat'\n",
      "  Position 21: ','\n",
      "  Position 22: ' a'\n",
      "  Position 23: ' crunchy'\n",
      "  Position 24: ' habit'\n",
      "  Position 25: '.'\n",
      "\n",
      "Starting analysis...\n",
      "============================================================\n",
      "\n",
      "--- Analyzing token position 18: 'A' ---\n",
      "Baseline continuation: A tasty treat, a crunchy habit....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26it [00:25,  1.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K=1     | neg=0.0000 | abs=0.0000\n",
      "K=10001 | neg=0.0376 | abs=0.3164\n",
      "K=20001 | neg=0.0947 | abs=0.3496\n",
      "K=30001 | neg=0.0947 | abs=0.2461\n",
      "K=40001 | neg=0.0947 | abs=0.2373\n",
      "K=50001 | neg=0.0947 | abs=0.2734\n",
      "K=60001 | neg=0.0947 | abs=0.2734\n",
      "K=70001 | neg=0.0947 | abs=0.2734\n",
      "K=80001 | neg=0.0947 | abs=0.2734\n",
      "Found minimum K for absolute effects: 10001 (metric: 0.3164, target: 0.1629)\n",
      "Found circuit with 10001 entries\n",
      "Found 5 tokens not in prompt: ['.', ' crunchy', ' tasty', ' habit', ' treat']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [00:05<00:00,  4.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3 clusters: ['.', 'treat', 'tasty']\n",
      "  🎯 Planning evidence found for: ['.', 'tasty']\n",
      "\n",
      "--- Analyzing token position 19: ' tasty' ---\n",
      "Baseline continuation:  tasty treat, a crunchy habit....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26it [00:25,  1.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K=1     | neg=0.0000 | abs=0.0000\n",
      "K=10001 | neg=0.9258 | abs=0.0173\n",
      "K=20001 | neg=0.8906 | abs=0.0752\n",
      "K=30001 | neg=0.8828 | abs=0.0845\n",
      "K=40001 | neg=0.8828 | abs=0.0903\n",
      "K=50001 | neg=0.8828 | abs=0.1001\n",
      "K=60001 | neg=0.8828 | abs=0.1001\n",
      "K=70001 | neg=0.8828 | abs=0.1001\n",
      "K=80001 | neg=0.8828 | abs=0.1001\n",
      "Found minimum K for negative effects: 10001 (metric: 0.9258, target: 0.0554)\n",
      "Found minimum K for absolute effects: 20001 (metric: 0.0752, target: 0.0554)\n",
      "Found circuit with 10001 entries\n",
      "Found 5 tokens not in prompt: ['.', ' crunchy', ' tasty', ' habit', ' treat']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [00:05<00:00,  4.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3 clusters: ['.', 'tasty', 'habit']\n",
      "  🎯 Planning evidence found for: ['.', 'tasty']\n",
      "\n",
      "--- Analyzing token position 20: ' treat' ---\n",
      "Baseline continuation:  treat, a crunchy habit....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26it [00:25,  1.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K=1     | neg=0.0260 | abs=0.0260\n",
      "K=10001 | neg=0.9844 | abs=0.6250\n",
      "K=20001 | neg=0.9883 | abs=0.7578\n",
      "K=30001 | neg=0.9883 | abs=0.7305\n",
      "K=40001 | neg=0.9883 | abs=0.7305\n",
      "K=50001 | neg=0.9883 | abs=0.6992\n",
      "K=60001 | neg=0.9883 | abs=0.6992\n",
      "K=70001 | neg=0.9883 | abs=0.6992\n",
      "K=80001 | neg=0.9883 | abs=0.6992\n",
      "Found minimum K for negative effects: 10001 (metric: 0.9844, target: 0.3680)\n",
      "Found minimum K for absolute effects: 10001 (metric: 0.6250, target: 0.3680)\n",
      "Found circuit with 10001 entries\n",
      "Found 4 tokens not in prompt: ['.', ' crunchy', ' habit', ' treat']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [00:05<00:00,  4.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 clusters: ['.', 'treat']\n",
      "  🎯 Planning evidence found for: ['.', 'treat']\n",
      "\n",
      "--- Analyzing token position 21: ',' ---\n",
      "Baseline continuation: , a crunchy habit....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26it [00:25,  1.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K=1     | neg=0.5898 | abs=0.5898\n",
      "K=10001 | neg=1.0000 | abs=0.3691\n",
      "K=20001 | neg=1.0000 | abs=0.3906\n",
      "K=30001 | neg=1.0000 | abs=0.3438\n",
      "K=40001 | neg=1.0000 | abs=0.3652\n",
      "K=50001 | neg=1.0000 | abs=0.3418\n",
      "K=60001 | neg=1.0000 | abs=0.3418\n",
      "K=70001 | neg=1.0000 | abs=0.3418\n",
      "K=80001 | neg=1.0000 | abs=0.3418\n",
      "Found minimum K for negative effects: 1 (metric: 0.5898, target: 0.3000)\n",
      "Found minimum K for absolute effects: 1 (metric: 0.5898, target: 0.3000)\n",
      "Found circuit with 1 entries\n",
      "Found 3 tokens not in prompt: ['.', ' crunchy', ' habit']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  4.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 clusters: []\n",
      "  ❌ No planning evidence found\n",
      "\n",
      "--- Analyzing token position 22: ' a' ---\n",
      "Baseline continuation:  a crunchy habit....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26it [00:25,  1.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K=1     | neg=0.3379 | abs=0.3379\n",
      "K=10001 | neg=0.9844 | abs=0.3594\n",
      "K=20001 | neg=0.9922 | abs=0.2461\n",
      "K=30001 | neg=0.9922 | abs=0.1533\n",
      "K=40001 | neg=0.9922 | abs=0.1846\n",
      "K=50001 | neg=0.9922 | abs=0.2236\n",
      "K=60001 | neg=0.9922 | abs=0.2236\n",
      "K=70001 | neg=0.9922 | abs=0.2236\n",
      "K=80001 | neg=0.9922 | abs=0.2236\n",
      "Found minimum K for negative effects: 1 (metric: 0.3379, target: 0.1711)\n",
      "Found minimum K for absolute effects: 1 (metric: 0.3379, target: 0.1711)\n",
      "Found circuit with 1 entries\n",
      "Found 3 tokens not in prompt: ['.', ' crunchy', ' habit']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  4.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 clusters: []\n",
      "  ❌ No planning evidence found\n",
      "\n",
      "--- Analyzing token position 23: ' crunchy' ---\n",
      "Baseline continuation:  crunchy habit....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26it [00:25,  1.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K=1     | neg=0.0000 | abs=0.0000\n",
      "K=10001 | neg=0.9180 | abs=0.0211\n",
      "K=20001 | neg=0.9023 | abs=0.0474\n",
      "K=30001 | neg=0.8867 | abs=0.0525\n",
      "K=40001 | neg=0.8867 | abs=0.0613\n",
      "K=50001 | neg=0.8867 | abs=0.0703\n",
      "K=60001 | neg=0.8867 | abs=0.0801\n",
      "K=70001 | neg=0.8867 | abs=0.0801\n",
      "K=80001 | neg=0.8867 | abs=0.0801\n",
      "Found minimum K for negative effects: 10001 (metric: 0.9180, target: 0.0902)\n",
      "Found circuit with 10001 entries\n",
      "Found 3 tokens not in prompt: ['.', ' crunchy', ' habit']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [00:05<00:00,  4.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 clusters: ['.', 'habit']\n",
      "  🎯 Planning evidence found for: ['.']\n",
      "\n",
      "--- Analyzing token position 24: ' habit' ---\n",
      "Baseline continuation:  habit....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26it [00:25,  1.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K=1     | neg=0.0000 | abs=0.0000\n",
      "K=10001 | neg=0.9883 | abs=0.1875\n",
      "K=20001 | neg=0.9883 | abs=0.3594\n",
      "K=30001 | neg=0.9883 | abs=0.5547\n",
      "K=40001 | neg=0.9883 | abs=0.5859\n",
      "K=50001 | neg=0.9883 | abs=0.5820\n",
      "K=60001 | neg=0.9883 | abs=0.5234\n",
      "K=70001 | neg=0.9883 | abs=0.5234\n",
      "K=80001 | neg=0.9883 | abs=0.5234\n",
      "Found minimum K for negative effects: 10001 (metric: 0.9883, target: 0.3305)\n",
      "Found minimum K for absolute effects: 20001 (metric: 0.3594, target: 0.3305)\n",
      "Found circuit with 10001 entries\n",
      "Found 2 tokens not in prompt: ['.', ' habit']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [00:05<00:00,  4.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 clusters: ['.', 'habit']\n",
      "  🎯 Planning evidence found for: ['.']\n",
      "\n",
      "--- Analyzing token position 25: '.' ---\n",
      "Baseline continuation: ....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26it [00:25,  1.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K=1     | neg=0.2539 | abs=0.2539\n",
      "K=10001 | neg=0.9648 | abs=0.9727\n",
      "K=20001 | neg=0.9609 | abs=0.9727\n",
      "K=30001 | neg=0.9727 | abs=0.9531\n",
      "K=40001 | neg=0.9727 | abs=0.9102\n",
      "K=50001 | neg=0.9727 | abs=0.9531\n",
      "K=60001 | neg=0.9727 | abs=0.9414\n",
      "K=70001 | neg=0.9727 | abs=0.9414\n",
      "K=80001 | neg=0.9727 | abs=0.9414\n",
      "Found minimum K for negative effects: 10001 (metric: 0.9648, target: 0.5531)\n",
      "Found minimum K for absolute effects: 10001 (metric: 0.9727, target: 0.5531)\n",
      "Found circuit with 10001 entries\n",
      "Found 1 tokens not in prompt: ['.']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [00:05<00:00,  4.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 clusters: ['.']\n",
      "  🎯 Planning evidence found for: ['.']\n"
     ]
    }
   ],
   "source": [
    "print(\"Running pipeline analysis on generated tokens...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Analyze the generated tokens (skip the prompt tokens)\n",
    "start_analysis = prompt_tokens.shape[-1]  # Start after the prompt (position 17)\n",
    "end_analysis = out_tokens.shape[-1]       # Go to the end (position 37)\n",
    "\n",
    "print(f\"Analyzing token positions {start_analysis} to {end_analysis-1}\")\n",
    "print(f\"Tokens to analyze:\")\n",
    "for i in range(start_analysis, end_analysis):\n",
    "    token_text = model.to_string(out_tokens[0, i:i+1])\n",
    "    print(f\"  Position {i}: '{token_text}'\")\n",
    "\n",
    "print(\"\\nStarting analysis...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Run the analysis\n",
    "analysis_results = run_poem_pipeline_analysis(\n",
    "    model=model,\n",
    "    saes=saes,\n",
    "    out_tokens=out_tokens,\n",
    "    start_pos=start_analysis,\n",
    "    end_pos=end_analysis,\n",
    "    verbose=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42dd9f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acba9c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "640962ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c07037f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce4359b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb189ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "finetuning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
